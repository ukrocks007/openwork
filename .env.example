# AI Configuration (choose one provider)
AI_API_KEY=your_api_key_here
AI_PROVIDER=openai

# For Ollama (local AI provider)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:0.5b

# AI Model Selection
# OpenAI: gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-sonnet-20240229, claude-2.1  
# Ollama: llama2, codellama, mistral, etc.
AI_MODEL=gpt-4

# AI Settings
AI_TEMPERATURE=0.3
AI_ENABLED=true
FALLBACK_TO_RULE_BASED=true

# Cache and Performance
AI_CACHE_TTL=3600